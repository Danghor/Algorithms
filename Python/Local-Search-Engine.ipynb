{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100%; !important } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#autosave 0\n",
    "from IPython.core.display import HTML, display\n",
    "display(HTML('<style>.container { width:100%; !important } </style>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Local Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows one important application of <em style=\"color:blue;\">dictionaries</em> and <em style=\"color:blue;\">sets</em>:\n",
    "It implements a *local search engine* that can be used to index `.pdf` documents on the local file system.  The index can then be used to search for all documents that contain specified words.  The main data structure used is a so called \n",
    "<em style=\"color:blue;\">inverted index</em>, which is a <em style=\"color:blue;\">dictionary</em> mapping words to the \n",
    "<em style=\"color:blue;\">sets</em> of documents that contain these words.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The module `subprocess` enables us to execute shell command and to capture their output via a *pipe* from which we can read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `get_text` takes a `path` specifiying a `.pdf` file.  It converts the `.pdf` file into a text file and returns the \n",
    "resulting text.  This function assumes that the program `pdftotext` is installed.  This program can be dowloaded at\n",
    "<a href=\"https://www.xpdfreader.com/download.html\">https://www.xpdfreader.com/download.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    command = ['pdftotext', '-enc', 'ASCII7', path, '-']\n",
    "    process = subprocess.Popen(command, stdout=subprocess.PIPE)\n",
    "    Lines   = process.stdout.readlines()\n",
    "    return ''.join([str(line, 'utf-8', 'ignore') for line in Lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this for one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17582\n",
      "CPU times: user 1.58 ms, sys: 3.73 ms, total: 5.31 ms\n",
      "Wall time: 61.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = get_text('../Literature/DualPivotQuicksort.pdf')\n",
    "print(len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to split the text contained in a file into words, we need the *regular expressions* provided by the module `re`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `tokenize` takes a string `s` and returns the set of words that have been found in the string `s`.  We assume that the words contain only latin characters.  Furthermore, we convert the words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(s):\n",
    "    return set(t.lower() for t in re.findall(r'[A-Za-z]+', s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check how many different words occur in the file that we have read above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the module `os` to traverse directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Document` represents a single file.  This class maintains three member variables:\n",
    "  - `path`  is the absolut file path specifying the location of the file containing the `pdf` document,\n",
    "  - `docID` is a natural number that serves as a unique identifier for the document,\n",
    "  - `Words` is the set of words contained in the file.\n",
    "  \n",
    "This class only serves as a container of its member variables, hence it has no methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, path, docID, Words):\n",
    "        self.path  = path\n",
    "        self.docID = docID\n",
    "        self.Words = Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `Index` contains three member variables:\n",
    "  - `InvertedIndex` is a dictionary that maps every word to the set of documents containing this word.\n",
    "    In this set, the documents are represented by their unique identifiers.\n",
    "  - `ID2Doc` is a dictionary mapping the document identifiers to the corresponding `Document` objects.\n",
    "  - `fileCount` is a counter that is needed to create unique document identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Index:\n",
    "    def __init__(self):\n",
    "        self.InvertedIndex = {}\n",
    "        self.ID2Doc        = {}\n",
    "        self.fileCount     = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method $\\texttt{self}.\\texttt{buildIndex}(d)$ takes an `Index` $\\texttt{self}$ and a directory $d$.  It traverses the directory $d$ recursively and collects all `.pdf` files contained in $d$ and its subdirectories.  These files are converted to text and their words are added to the `InvertedIndex`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildIndex(self, directory):   \n",
    "    for root, _, files in os.walk(directory):\n",
    "        for fileName in files:\n",
    "            if fileName[-4:] == '.pdf':\n",
    "                fullpath = os.path.abspath(os.path.join(root, fileName))\n",
    "                print('indexing', fullpath, end=' has ')\n",
    "                try:\n",
    "                    fileText = get_text(fullpath)\n",
    "                    tokenSet = tokenize(fileText)\n",
    "                    print(len(tokenSet), 'different words.')\n",
    "                    self.fileCount += 1\n",
    "                    document = Document(fullpath, self.fileCount, tokenSet)\n",
    "                    self.ID2Doc[self.fileCount] = document\n",
    "                    self._addToIndex(self.fileCount, tokenSet)\n",
    "                except:\n",
    "                    print('unable to read', path)\n",
    "                    continue\n",
    "    for root, directory, _ in os.walk(directory):\n",
    "        path = os.path.abspath(os.path.join(root, fileName))\n",
    "        self.buildIndex(path)\n",
    "        \n",
    "Index.buildIndex = buildIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `_addToIndex` takes a document identifier $d$ and a set of words $W$ occurring in the document specified by $d$ and extends the `InvertedIndex` so that for every word $w$ in `Words` we have that\n",
    "$$ d \\in \\texttt{InvertedIndex}[w]. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _addToIndex(self, documentID, Words):\n",
    "    for term in Words:\n",
    "        try:\n",
    "            docSet = self.InvertedIndex[term]\n",
    "            docSet.add(documentID)\n",
    "        except:\n",
    "            self.InvertedIndex[term] = { documentID }\n",
    "        \n",
    "Index._addToIndex = _addToIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method $\\texttt{self}.\\texttt{retrieve}(Q)$ takes an Index `self` and a query $Q$.  $Q$ is a string containing multiple words. \n",
    "The method returns the set of those documents that contain all the words occurring in $Q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(self, Query):\n",
    "    SearchStrings = list(tokenize(Query))\n",
    "    result        = set()\n",
    "    Documents     = self.InvertedIndex.get(SearchStrings[0], set())\n",
    "    for word in SearchStrings[1:]:\n",
    "        Documents &= self.InvertedIndex.get(word, set())           \n",
    "    return Documents\n",
    "\n",
    "Index.retrieve = retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/topological-sorting-kahn.pdf has 896 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/LempelZivReport.pdf has 816 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/lics04-transition-invariants.pdf has 1022 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/p50-liskov.pdf has 1416 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/DualPivotQuicksort.pdf has 461 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/welch.pdf has 0 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/2-3-trees.pdf has 483 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/p467-mcilroy.pdf has 1103 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/mergesort_NJC.pdf has 2896 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/dzhang_splaytree.pdf has 189 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/insertion-sort.pdf has 645 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/cacm09-proving-program-termination.pdf has 1339 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/p743-demaine.pdf has 1220 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/ramsey.pdf has 992 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/bdd97.pdf has 1469 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/qsort.pdf has 1471 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/ramseyorig.pdf has 1007 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/bdd-bryant.pdf has 1698 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/p360-bentley.pdf has 1324 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/splay-trees-sleator-tarjan.pdf has 1677 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/big-graph-nsa.pdf has 694 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/macKay.pdf has 8948 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/introduction-algorithms-cormen.pdf has 8220 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/algorithms-sedgewick.pdf has 6240 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/Mehlhorn-Sanders-Toolbox.pdf has 6138 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/data-structures-and-network-algorithms-tarjan.pdf has 3457 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/dasgupta.pdf has 5650 different words.\n",
      "indexing /Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/data-structures-and-algorithms-ahu.pdf has 4786 different words.\n",
      "CPU times: user 685 ms, sys: 106 ms, total: 791 ms\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = Index()\n",
    "index.buildIndex(\"../Literature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def query(Q):\n",
    "    result = set()\n",
    "    for docID in index.retrieve(Q):\n",
    "        result.add(index.ID2Doc[docID].path)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/Mehlhorn-Sanders-Toolbox.pdf',\n",
       " '/Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/algorithms-sedgewick.pdf',\n",
       " '/Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/data-structures-and-algorithms-ahu.pdf',\n",
       " '/Users/karlstroetmann/Dropbox/Kurse/Algorithms/Literature/Books/introduction-algorithms-cormen.pdf'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(\"trie avl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
