\chapter{Sets and Maps}
During the first term we have seen how important sets and functional relations are.  In the
following, functional relations will be called \emph{maps}.  In this chapter we show how sets and
maps can be implemented efficiently.  We confine our attention to the implementation of maps.  The
reason is that a set $M$ can always be represented by its \emph{characteristic function}:  If $M$ is
a set, then the characteristic function $\chi_M$ is defined such that
\\[0.2cm]
\hspace*{1.3cm}
$x \in M \Leftrightarrow \chi_M(x) = \mathtt{true}$
\\[0.2cm]
holds true.  In order to implement a set $M$ we can therefore implement its characteristic function
as a map.  The rest of this chapter is organized as follows:
\begin{enumerate}
\item We begin with the definition of the abstract data type of a \emph{map.}
    
      Following this definition we present several different implementations of maps. 
\item We start our discussion with \emph{ordered binary trees}.  The average complexity of inserting
      an element into an ordered binary tree is logarithmic.  Unfortunately, the worst case complexity
      is linear in the size of the ordered binary tree.
\item Next, we discuss \emph{balanced ordered trees}.  In the case of balanced ordered trees the
      complexity of insertion is always logarithmic.
\item After that, we discuss so called \emph{tries}.  These can be used as maps if the keys to be
      stored in the map are strings.
\item Finally, we discuss \textsl{hash tables}.  Hash tables provide another way to implement a map.
      Although I personally think that hash tables are a bit overrated, they are in wide spread use
      and therefore every computer scientist should have a good understanding of their inner workings.
\end{enumerate}

\section[ADT Map]{The Abstract Data Type \emph{Map}} 
Many applications require the efficient maintenance of some mapping of \emph{keys} to
\emph{values}.  For example, in order to implement a software analog of a telephone book we have to
be able to associate numbers with names.  In this case, the name of a person is regarded as a
\emph{key} and the telephone number is the value that gets associated with the key.
The most important functions provided by a telephone directory are the following:
\begin{enumerate}
\item \textsl{Lookup}: We have to be able to look up a given name and return the telephone number
      associated with this name.
\item \textsl{Insertion}: We need to be able to insert a new name and the corresponding telephone
      number into our directory.
\item \textsl{Deletion}: The final requirement is that it has to be possible to delete names from
      the directory.
\end{enumerate}


\begin{Definition}[Map] \hspace*{\fill} \\
{\em
  The abstract data type of a \emph{map} is defined as follows:
  \begin{enumerate}
  \item The name is \textsl{Map}.
  \item The set of type parameters is $\{ \textsl{Key}, \textsl{Value} \}$.
  \item The set of function symbols is \\[0.1cm]
       \hspace*{1.3cm} 
       $\{ \textsl{map}, \textsl{find}, \textsl{insert}, \textsl{delete} \}$.
  \item The signatures of these function symbols are as follows:
        \begin{enumerate}
        \item $\textsl{map}: \textsl{Map}$

              Calling $\textsl{map}()$ generates a new empty map.  Here, an empty map is a map that
              does not store any keys.
        \item $\textsl{find}: \textsl{Map} \times \textsl{Key} \rightarrow \textsl{Value} \cup \{\Omega\}$

              The function call
              \\[0.2cm]
              \hspace*{1.3cm}
              $m.\textsl{find}(k)$ 
              \\[0.2cm]
              checks whether the key $k$ is stored in the map $m$.  If this is the case, the
              value associated with this key is returned, otherwise the function call returns
              the special value $\Omega$.
        \item $\textsl{insert}: \textsl{Map} \times \textsl{Key} \times \textsl{Value} \rightarrow \textsl{Map}$

              The function call
              \\[0.2cm]
              \hspace*{1.3cm}
              $m.\textsl{insert}(k,v)$ 
              \\[0.2cm]
              takes a key $k$ and an associated value $v$ and stores this information into the map
              $m$.  If the map $m$ already stores a values associated with the key $k$, this value
              is overwritten.  

              The function call returns the resulting map.
        \item $\textsl{delete}: \textsl{Map} \times \textsl{Key} \rightarrow \textsl{Map}$

              The function call
              \\[0.2cm]
              \hspace*{1.3cm}
              $m.\textsl{delete}(k)$ 
              \\[0.2cm]
              removes the key $k$ from the map $m$.  If the map $m$ does not contain a value for the
              key $k$, then the unchanged map is returned.

              The function call returns the new map. 
        \end{enumerate}
  \item The behavior of a map is specified via the following axioms.
        \begin{enumerate}
        \item $\textsl{map}().\textsl{find}(k) = \Omega$.

              Calling $\textsl{map}()$ generates an empty map which does not have any keys stored.
              Hence, looking up any key will just return the undefined value.
        \item $m.\textsl{insert}(k, v).\textsl{find}(k) = v$.

              If a value $v$ is inserted for a key $k$, then when we look up this key $k$ the corresponding value
              $v$ will be returned.
        \item $k_1 \not= k_2 \rightarrow m.\textsl{insert}(k_1, v).\textsl{find}(k_2) = m.\textsl{find}(k_2)$.

              If a value is inserted for a key $k_1$, then this does not change the values that are stored
              for any key that is different from $k_1$.
        \item $m.\textsl{delete}(k).\textsl{find}(k\bigr) = \Omega$.

              If the key $k$ is deleted, then afterwords we won't find this key anymore.
        \item $k_1 \not= k_2 \rightarrow 
               m.\textsl{delete}(k_1).\textsl{find}(k_2) = m.\textsl{find}(k_2)$,

              If  we delete a key $k_1$ and then try to look up the information stored under a key
              $k_2$ that is different from $k_1$, we will get the same result that we would have got
              if we had searched for $k_2$ before deleting $k_1$.
              \eox
        \end{enumerate}
  \end{enumerate}
}
\end{Definition}

In \textsc{SetlX} it is very easy to implement the abstract data type  \textsl{map}.  We just have
to realize that a map is the same thing as a function and we have already seen that functions can
be interpreted as binary relations.
Now if $r$ is a binary relation that, for a given key $k$,  contains exactly one pair of the form
$[k,v]$, then the expression
\\[0.1cm]
\hspace*{1.3cm} $r[k]$
\\[0.1cm]
returns the value $v$.  On the other hand we can insert the pair $[k,v]$ into the relation $r$ by
writing
\\[0.1cm]
\hspace*{1.3cm} $r[k] := v$\texttt{;} \\[0.1cm]
In order to delete the value stored for a key  $k$ it is sufficient to assign the undefined value
$\Omega$ to the key $k$ as follows: \\[0.1cm]
\hspace*{1.3cm} $r[k] := \mathtt{om}$. \\[0.1cm]
This value $\Omega$ is also the value that is returned by the expression  $r[k]$ if
the binary  relation $r$ has no pair of the form $[k,v]$.
Figure  \ref{fig:map-trivial.stlx} presents an implementation of maps along these lines.


\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
    class map() {
        mRelation := {};
      static {
        find   := k |-> mRelation[k];
        insert := procedure(k, v) { mRelation[k] := v;  };
        delete := procedure(k)    { mRelation[k] := om; };
      }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{A trivial implementation of the abstract data type \textsl{Map} in \textsc{SetlX}.}
  \label{fig:map-trivial.stlx}
\end{figure} 


\section{Geordnete binäre Bäume}
Falls auf der Menge \textsl{Key} der Schlüssel eine totale Ordnung $\leq$ existiert, so kann
eine einfache und zumindest im statistischen Durchschnitt effiziente Implementierung des
abstrakte Daten-Typs \textsl{Map} mit Hilfe \emph{geordneter binärer Bäume} erfolgen.
Um diesen Begriff definieren zu können, führen wir zunächst \emph{binäre Bäume} ein.

\begin{Definition}[Binäre Bäume] \hspace*{\fill} \\
{\em
  Gegeben sei eine Menge $\textsl{Key}$ von Schlüsseln und eine Menge $\textsl{Value}$ von
  Werten.  Dann definieren wir
  die Menge der binären Bäume $\Bin$ induktiv mit Hilfe der
  beiden Funktions-Zeichen \textsl{Nil} und \textsl{Node}, deren Typ-Spezifikationen 
  wie folgt gegeben sind: \\[0.1cm]
  \hspace*{1.3cm} 
  $\textsl{Nil}: \Bin$ \qquad und \qquad  $\textsl{Node}: \textsl{Key} \times \textsl{Value} \times \Bin \times \Bin \rightarrow \Bin$.
  \begin{enumerate}
  \item $\textsl{Nil}$ ist ein binärer Baum.

        Dieser Baum wird als der \emph{leere Baum} bezeichnet.
  \item $\textsl{Node}(k, v, l, r)$ ist ein binärer Baum, falls gilt: 
        \begin{enumerate}
        \item $k$ ist ein Schlüssel aus der Menge $\textsl{Key}$.
        \item $v$ ist ein Wert aus der Menge $\textsl{Value}$.
        \item $l$ ist ein binärer Baum.

              $l$ wird als der \emph{linke Teilbaum} von $\textsl{Node}(k, v, l, r)$ bezeichnet.
        \item $r$ ist ein binärer Baum.

              $r$ wird als der \emph{rechte Teilbaum} von $\textsl{Node}(k, v, l, r)$ bezeichnet.
              \hspace*{\fill} $\Box$
        \end{enumerate}
  \end{enumerate}
}
\end{Definition}

\noindent
Als nächstes definieren wir, was wir unter einem \emph{geordneten binären Baum} verstehen.
\begin{Definition}[Geordnete binäre Bäume] \hspace*{\fill} \\
{\em
  Die Menge $\Bin_<$ der \emph{geordneten binären Bäume} wird induktiv definiert.
  \begin{enumerate}
  \item $\textsl{Nil} \in \Bin_<$
  \item $\textsl{Node}(k, v, l, r) \in \Bin_<$ \quad falls folgendes gilt:
        \begin{enumerate}
        \item $k$ ist ein Schlüssel aus der Menge $\textsl{Key}$.
        \item $v$ ist ein Wert aus der Menge $\textsl{Value}$.
        \item $l$ und $r$ sind geordnete binäre Bäume.
        \item Alle Schlüssel, die in dem linken Teilbaum $l$ auftreten,
              sind kleiner als $k$.
        \item Alle Schlüssel, die in dem rechten Teilbaum $r$ auftreten,
              sind größer als $k$.
        \end{enumerate}
        Die beiden letzten  Bedingungen bezeichnen wir als die \emph{Ordnungs-Bedingung}.
        \hspace*{\fill} $\Box$
  \end{enumerate}
}  
\end{Definition}
Geordnete binäre Bäume lassen sich grafisch wir folgt darstellen:
\begin{enumerate}
\item Der leere Baum \textsl{Nil} wird durch einen dicken schwarzen Punkt dargestellt.
\item Ein Baum der Form $\textsl{Node}(k,v,l,r)$ wird dargestellt,  indem zunächst ein
      Oval gezeichnet wird, in dem oben der Schlüssel $k$ und darunter, getrennt durch
      einen waagerechten Strich, der dem Schlüssel zugeordnete Wert $v$ eingetragen wird.
      Dieses Oval bezeichnen wir auch als einen \emph{Knoten} des binären Baums.
      Anschließend wird links unten von diesem Knoten rekursiv der Baum $l$ ge\-zeich\-net
      und  rechts unten wird rekursiv der Baum $r$ gezeichnet. Zum Abschluss zeichnen wir
      von dem mit $k$ und $v$ markierten Knoten jeweils einen Pfeil zu dem linken und dem
      rechten Teilbaum.
\end{enumerate}
Abbildung \ref{fig:graph1} zeigt ein Beispiel für einen
geordneten binären Baum.  Der oberste Knoten, in der Abbildung ist das der mit dem Schlüssel
$8$ und dem Wert $22$ markierte Knoten, wird als die \emph{Wurzel} des Baums bezeichnet.
Ein \emph{Pfad der Länge} $k$ in dem Baum ist eine Liste $[n_0,n_1, \cdots, n_k]$ von
$k+1$ Knoten, die durch Pfeile verbunden sind. Identifizieren wir Knoten mit ihren
Markierungen, so ist \\[0.1cm]
\hspace*{1.3cm} $\bigl[ \pair(8,22), \pair(12,18), \pair(10,16), \pair(9,39) \bigr]$ \\[0.1cm]
ein Pfad der Länge 3.


\begin{figure}[!ht]
  \centering
  \framebox{\epsfig{file=Abbildungen/graph1.eps}} 
  \caption{Ein geordneter binärer Baum}
  \label{fig:graph1}
\end{figure}


Wir überlegen uns nun, wie wir mit Hilfe geordneter binärer Bäume den ADT \textsl{Map}
implementieren können.  Wir spezifizieren die einzelnen Methoden dieses Daten-Typs durch
bedingte Gleichungen.  Der Konstruktor $\textsl{map}()$ liefert als Ergebnis den leeren Baum zurück:
\[ \textsl{map}() = \textsl{Nil}. \]
Für die Methode $\textsl{find}()$ erhalten wir die folgenden Gleichungen:
\begin{enumerate}
\item $\textsl{Nil}.\textsl{find}(k) = \Omega$,

      denn der leere Baum repräsentiert die leere Abbildung.
\item $\textsl{Node}(k, v, l, r).\textsl{find}(k) = v$,

      denn der Knoten $\textsl{Node}(k,v,l,r)$ speichert die Zuordnung $k \mapsto v$.
\item $k_1 < k_2 \rightarrow \textsl{Node}(k_2, v, l, r).\textsl{find}(k_1) = l.\textsl{find}(k_1)$,

      denn wenn $k_1$ kleiner als $k_2$ ist, dann kann aufgrund der Ordnungs-Bedingung
      eine Zuordnung für $k_1$ nur in dem linken Teilbaum $l$ gespeichert sein.
\item $k_1 > k_2 \rightarrow \textsl{Node}(k_2, v, l, r).\textsl{find}(k_1) = r.\textsl{find}(k_1)$,

      denn wenn $k_1$ größer als $k_2$ ist, dann kann aufgrund der Ordnungs-Bedingung
      eine Zuordnung für $k_1$ nur in dem rechten Teilbaum $r$ gespeichert sein.
\end{enumerate}
Als nächstes definieren wir die Funktion \textsl{insert}.  Die Definition erfolgt
ebenfalls mit Hilfe rekursiver Gleichungen und ist ganz analog zur Definition der 
Funktion \textsl{find}.
\begin{enumerate}
\item $\textsl{Nil}.\textsl{insert}(k,v) = \textsl{Node}(k,v, \textsl{Nil}, \textsl{Nil})$,
  
      denn wenn der Baum vorher leer ist, so kann die einzufügende Information direkt an
      der Wurzel abgespeichert werden.
\item $\textsl{Node}(k,v_2,l,r).\textsl{insert}(k,v_1) = \textsl{Node}(k, v_1, l, r)$,

      denn wenn wir den Schlüssel $k$ an der Wurzel finden, überschreiben wir einfach den zugeordneten 
      Wert.
\item $k_1 < k_2 \rightarrow 
         \textsl{Node}(k_2, v_2, l, r).\textsl{insert}(k_1, v_1) = \textsl{Node}(k_2, v_2, l.\textsl{insert}(k_1, v_1), r)$,

      denn wenn der Schlüssel $k_1$, unter dem wir Informationen einfügen wollen, kleiner
      als der Schlüssel $k_2$ an der Wurzel ist, so müssen wir die einzufügende
      Information im linken Teilbaum einfügen.
\item $k_1 > k_2 \rightarrow 
         \textsl{Node}(k_2, v_2, l, r).\textsl{insert}(k_1, v_1) = 
         \textsl{Node}(k_2, v_2, l, r.\textsl{insert}(k_1, v_1))$,

      denn wenn der Schlüssel $k_1$, unter dem wir Informationen einfügen wollen, größer
      als der Schlüssel $k_2$ an der Wurzel ist, so müssen wir die einzufügende
      Information im rechten Teilbaum einfügen.
\end{enumerate}
Als letztes definieren wir die Methode \textsl{delete}. Diese Definition ist schwieriger als
die Implementierung der andern beiden Methoden.  Falls wir in einen Baum der Form
$t =\textsl{Node}(k,v,l,r)$ den Eintrag mit dem Schlüssel $k$ löschen wollen, so
kommt es auf die beiden Teilbäume $l$ und $r$ an.  Ist $l$ der leere Teilbaum,
so liefert $t.\textsl{delete}(k)$ als Ergebnis den Teilbaum $r$ zurück.
Ist $r$ der leere Teilbaum, so ist das Ergebnis $l$.  Problematisch ist die Situation,
wenn weder $l$ noch $r$ leer sind.  
Die Lösung besteht dann darin, dass wir in dem rechten
Teilbaum $r$ den Knoten mit dem kleinsten Schlüssel suchen und diesen Knoten aus dem
Baum $r$ entfernen.  Den dadurch entstehenden Baum nennen wir $r'$.
 Anschließend überschreiben wir in $t =\textsl{Node}(k,v,l,r')$ die
Werte $k$ und $v$ mit dem eben gefundenen kleinsten Schlüssel $k_{min}$ und dem $k_{min}$
zugeordneten Wert $v_{min}$.  Der dadurch entstehende binäre Baum 
$t=\textsl{Node}(k_{min},v_{min},l,r')$
 ist auch wieder
geordnet, denn einerseits ist der Schlüssel $k_{min}$  größer als der Schlüssel $k$ und
damit sicher auch größer als alle Schlüssel im linken Teilbaum $l$ und andererseits ist
$k_{min}$ kleiner als alle  Schlüssel im Teilbaum $r'$, denn $k_{min}$ ist ja der
kleinste Schlüssel aus $r$.  

Zur Veranschaulichung betrachten wir ein Beispiel: Wenn wir in dem Baum aus Abbildung 
\ref{fig:graph1} den Knoten mit der Markierung $\pair(4,16)$ löschen wollen,
so suchen wir zunächst in dem Teilbaum, dessen Wurzel mit $\pair(6,36)$ markiert ist, den
Knoten, der mit dem kleinsten Schlüssel markiert ist.  Dies ist der Knoten mit der
Markierung $\pair(5,25)$.  Wir löschen diesen Knoten und überschreiben die Markierung
$\pair(4,16)$ mit der Markierung $\pair(5,25)$.  Abbildung 
\ref{fig:graph2} auf Seite \pageref{fig:graph2} zeigt das Ergebnis.

\begin{figure}[!th]
  \centering
  \framebox{\epsfig{file=graph2.eps}} 
  \caption{Der geordnete binärer Baum aus Abbildung 
          \ref{fig:graph1} nach dem Entfernen des Knotens mit der Markierung $\pair(4,16)$.}
  \label{fig:graph2}
\end{figure}

Wir geben nun bedingte Gleichungen an, welche die Methode \textsl{delMin} spezifizieren.
\begin{enumerate}
\item $\textsl{Node}(k, v, \textsl{Nil}, r).\textsl{delMin}() = [r, k, v]$,

      denn wenn der linke Teilbaum leer ist, muss $k$ der kleinste Schlüssel in 
      dem Baum sein.  Wenn wir diesen  Schlüssel nebst dem zugehörigen Wert aus dem Baum
      entfernen, bleibt der rechte Teilbaum übrig.
\item $l\not= \textsl{Nil} \wedge l.\textsl{delMin}() = [l',k_{min}, v_{min}] \;\rightarrow$ \\[0.1cm]
       \hspace*{1.3cm} 
       $\textsl{Node}(k, v, l, r).\textsl{delMin}() = [\textsl{Node}(k, v, l', r), k_{min}, v_{min}]$,

      denn wenn der linke Teilbaum $l$ in dem binären Baum $t = \textsl{Node}(k, v, l, r)$
      nicht leer ist, so muss der kleinste Schlüssel von $t$ in $l$ liegen.
      Wir entfernen daher rekursiv den kleinsten Schlüssel aus $l$ und erhalten dabei den
      Baum $l'$.  In dem ursprünglich gegebenen Baum $t$ ersetzen wir $l$ durch $l'$ und erhalten
      $t = \textsl{Node}(k, v, l', r)$.
\end{enumerate}
Damit können wir nun die Methode $\mathtt{delete}()$ spezifizieren.
\begin{enumerate}
\item $\textsl{Nil}.\textsl{delete}(k) = \textsl{Nil}$.
\item $\textsl{Node}(k,v,\textsl{Nil},r).\textsl{delete}\bigl(k\bigr) = r$.
\item $\textsl{Node}(k,v,l,\textsl{Nil}).\textsl{delete}(k) = l$.
\item $l \not= \textsl{Nil} \,\wedge\, r \not= \textsl{Nil} \,\wedge\, r.\textsl{delMin}() = [r',k_{min}, v_{min}]  \;\rightarrow$ \\[0.1cm]
      \hspace*{1.3cm}
      $\textsl{Node}(k,v,l,r).\textsl{delete}(k) = \textsl{Node}(k_{min},v_{min},l,r')$.
      
      Falls der zu entfernende Schlüssel mit dem Schlüssel an der Wurzel des Baums
      übereinstimmt,  entfernen wir mit dem Aufruf $r\mathtt{.}\textsl{delMin}()$
      den kleinsten Schlüssel aus dem rechten Teilbaum  $r$ und produzieren dabei den Baum $r'$.
      Gleichzeitig berechnen wir dabei für den rechten Teilbaum den kleinsten Schlüssel $k_{min}$ und den
      diesem Schlüssel zugeordneten Wert $v_{min}$.  Diese Werte setzen wir nun an die
      Wurzel des neuen Baums.

\item $k_1 < k_2 \rightarrow \textsl{Node}(k_2,v_2,l,r).\textsl{delete}\bigl(k_1) = 
       \textsl{Node}(k_2,v_2,l.\textsl{delete}(k_1),r)$.

      Falls der zu entfernende Schlüssel kleiner ist als der Schlüssel an der Wurzel,
      so kann sich der Schlüssel nur im linken Teilbaum befinden.  Daher wird der
      Schlüssel $k_1$ rekursiv in dem linken Teilbaum $l$ entfernt.
\item $k_1 > k_2 \rightarrow \textsl{Node}(k_2,v_2,l,r).\textsl{delete}(k_1) = 
       \textsl{Node}(k_2,v_2,l,r.\textsl{delete}(k_1))$,

      denn in diesem Fall kann sich der Eintrag mit dem Schlüssel $k_1$  nur in dem
      rechten Teilbaum $r$ befinden.
\end{enumerate}

\subsection{Implementing Ordered Binary Trees in \textsc{SetlX}}
Figure \ref{fig:binary-tree.stlx-1} and Figure \ref{fig:binary-tree.stlx-2} show how ordered binary
trees can be implemented in \textsc{SetlX}.  Objects of class \texttt{map} encapsulate ordered
binary trees.  We discuss the implementation of this class next.
\begin{enumerate}
\item The constructor map is called with one argument.  This argument, called \texttt{cmp}
      in line 1, is a function representing a total order ''$<$''.  The idea is that the function
      \texttt{cmp} is called with two arguments and we have
      \\[0.2cm]
      \hspace*{1.3cm}
      $\mathtt{cmp}(x,y)$ \quad if and only if \quad $x < y$.
      \\[0.2cm]
      The function \texttt{cmp} is later stored in the member variable \texttt{mCmpFct} in line 6.
\item The class \texttt{map} represents a node in an ordered binary tree.  In order to do so, it
      maintains four additional member variables.
      \begin{enumerate}
      \item \texttt{mKey} is the key stored at this node.  For an empty node, \texttt{mKey}
            has the value \texttt{om}, which represents $\Omega$.
      \item \texttt{mValue} stores the value stored at this node.  For an empty node,
            \texttt{mValue} is \texttt{om}.
      \item \texttt{mLeft} is the left subtree.  An empty subtree is represented as \texttt{om}.
      \item \texttt{mRight} is the right subtree.  
      \end{enumerate}
\item The function \texttt{isEmpty} checks whether \texttt{this} represents an empty tree.
      The assumption is that if \texttt{mKey} is \texttt{om}, then the member variables
      \texttt{mValue}, \texttt{mLeft}, and \texttt{mRight} will also be \texttt{om}.
\item The implementation of \texttt{find} works as follows:
      \begin{enumerate}
      \item If the node is empty, there is no value to find and the function returns \texttt{om}.
            Note that in \textsc{SetlX} a \texttt{return} statement which does not return a value 
            automatically returns \texttt{om}.
      \item If the key we are looking for is stored at the root of this tree, the value stored for
            this key is \texttt{mValue}.
      \item Otherwise, we have to compare the key \texttt{k}, which is the key we are looking for,
            with the key \texttt{mKey}, which is the key stored in this node.  If \texttt{k}
            is less than \texttt{mKey}, \texttt{k} can at most be stored in the left subtree
            \texttt{mLeft}, while if $k$ is greater than \texttt{mKey}, \texttt{k} can only be
            stored in the right subtree.
      \end{enumerate}


\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.0cm,
                  xrightmargin  = 0.0cm
                ]
    class map(cmp) {
        mKey    := om;
        mValue  := om; 
        mLeft   := om;
        mRight  := om;
        mCmpFct := cmp;  // function to compare keys
      static {
        isEmpty := [] |-> mKey == om;
        find := procedure(k) {
            if      (isEmpty())        { return;                }
            else if (mKey == k)        { return mValue;         }
            else if (mCmpFct(k, mKey)) { return mLeft .find(k); }
            else                       { return mRight.find(k); }
        };
        insert := procedure(k, v) {
              if (isEmpty()) { 
                this.mKey   := k;
                this.mValue := v; 
                this.mLeft  := map(mCmpFct);
                this.mRight := map(mCmpFct);
            } else if (mKey == k) { 
                mValue := v; 
            } else if (mCmpFct(k, mKey)) { 
                mLeft .insert(k, v); 
            } else { 
                mRight.insert(k, v); 
            }
        };
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Implementierung geordneter Bäume in \textsc{SetlX}, 1.~Teil.}
  \label{fig:binary-tree.stlx-1}
\end{figure}
\item The implementation of \texttt{insert} is similar to the implementation of \texttt{find}.
      \begin{enumerate}
      \item If the binary tree is empty, we set the member variables \texttt{mKey} and
            \texttt{mValue} to the appropriate values.  The member variables \texttt{mLeft} and 
            \texttt{mRight} are initialized as empty trees.
      \item If the key \texttt{k} under which the value \texttt{v} is to be inserted is identical
            to the key \texttt{mKey} stored at this node, then we have found the node where we need
            to insert \texttt{v}.  In this case, \texttt{mValue} is overwritten with \texttt{v}.
      \item Otherwise, \texttt{k} is compared with \texttt{mKey} and the search is continued in the
            appropriate subtree.
      \end{enumerate}      


\begin{figure}[!ht]
  \centering
\begin{Verbatim}[ frame         = lines, 
                  framesep      = 0.3cm, 
                  firstnumber   = last,
                  labelposition = bottomline,
                  numbers       = left,
                  numbersep     = -0.2cm,
                  xleftmargin   = 0.8cm,
                  xrightmargin  = 0.8cm
                ]
        delMin := procedure() {
            if (mLeft.isEmpty()) { 
                return [ mRight, mKey, mValue ]; 
            } else {
                 [ ls, km, vm ] := mLeft.delMin();
                 this.mLeft := ls;
                 return [ this, km, vm ];
            }
        };
        delete := procedure(k) {
            if      (isEmpty())  { return; } 
            else if (k == mKey)  {
                if      (mLeft .isEmpty()) { update(r); }  
                else if (mRight.isEmpty()) { update(l); } 
                else {
                    [ rs, km, vm ] := mRight.delMin();
                    this.mKey   := km;
                    this.mValue := vm; 
                    this.mRight := rs;
                }
            } else if (mCmpFct(k, mKey)) {
                if (!mLeft .isEmpty()) { mLeft.delete(k); }
            } else {
                if (!mRight.isEmpty()) { mRight.delete(k); }
            }
        };
        update := procedure(t) {
            this.mKey   := t.mKey;
            this.mValue := t.mValue;
            this.mLeft  := t.mLeft;
            this.mRight := t.mRight;
        };
      }
    }
\end{Verbatim}
\vspace*{-0.3cm}
  \caption{Ordered binary trees in \textsc{SetlX}, part2.}
  \label{fig:binary-tree.stlx-2}
\end{figure}

\item The implementation of \texttt{delMin} and \texttt{delete} is done in a similar way as the
      implementation of \texttt{insert}.  It should be noted that the implementation follows directly from the
      equations derived  previously. 
\end{enumerate}

\begin{figure}[!th]
  \centering 
  \framebox{\epsfig{file=degenerated-bin-tree}} 
  \caption{Ein entarteter  geordneter binärer Baum.}
  \label{fig:degenerated}
\end{figure}


\subsection{Analyse der Komplexität}
In this section we will first discuss the worst case complexity, which is quite bad.  In fact, in
the worst case, the call $b.\mathtt{find}(k)$ will perform $\Oh(n)$ key comparisons if $b$ is an ordered
binary search tree of $n$ elements.  After that, we investigate the average case complexity.  We
will show that the average case complexity is $\Oh\bigr(\ln(n)\bigr)$.

\subsubsection{Worst Case Complexity}
Wir untersuchen zunächst die Komplexität der Funktion \textsl{find} im schlechtesten Fall.
Dieser Fall tritt dann ein, wenn der binäre Baum zu einer Liste entartet.  Abbildung
\ref{fig:degenerated} auf Seite \pageref{fig:degenerated} zeigt den geordneten binären Baum, der
dann entsteht, wenn die Paare aus Schlüssel und Werten aus der Abbildung
\ref{fig:graph1} in aufsteigender Reihenfolge eingegeben werden.  Wird hier nach dem
größten Schlüssel gesucht, so muss der komplette Baum durchlaufen werden.  Enthält der Baum
$n$ Schlüssel, so sind also insgesamt $n$ Vergleiche erforderlich.  In diesem Fall ist ein
geordneter binärer Baum also nicht besser als eine Liste.

\subsubsection{Average Case Complexity}
Erfreulicherweise tritt der schlechteste Fall im statistischen Durchschnitt selten auf.
Im Durchschnitt ist ein zufällig erzeugter binärer Baum recht gut balanciert, so dass 
beispielsweise für einen Aufruf von \texttt{find()} für einen Baum mit $n$ Schlüsseln
durchschnittlich  $\Oh\bigl(\ln(n)\bigr)$
Vergleiche erforderlich sind. Wir werden diese Behauptung nun beweisen.

%Dazu definieren wir auf binären Bäumen zunächst eine Funktion 
%\[ \textsl{height}: \Bin \rightarrow \N, \]
%die die Höhe eines binären Baums angibt.  Die Definition erfolgt induktiv.
%\begin{enumerate}
%\item $\textsl{Nil}.\textsl{height}() = 0$.

%      Der leere Baum hat die Höhe $0$.
%\item $\textsl{node}(k,v,l,r).\textsl{height}() = 
%       1 + \max\bigl(l.\textsl{height}(),\, r.\textsl{height}()\bigr)$.

%      Die Höhe des Baums $\textsl{node}(k,v,l,r)$ ist um eins größer als die Höhe des
%      größten Teilbaums.
%\end{enumerate}
%Analog definieren wir für einen binären Baum $b$ die Anzahl $b.\textsl{count}()$ der Schlüssel, die
%der Baum enthält.   Die Definition von $b.\textsl{count}()$ erfolgt durch Induktion nach $b$.
%\begin{enumerate}
%\item $\textsl{Nil}.\textsl{count}() = 0$.

%      Der leere Baum enthält keine Schlüssel.
%\item $\textsl{node}(k,v,l,r).\textsl{count}() = 
%       1 + l.\textsl{count}() + r.\textsl{height}()\bigr)$.

%      Der Baum $\textsl{node}(k,v,l,r)$ enthält zusätzlich zu dem Schlüssel $k$ die
%      Schlüssel aus den Teilbäumen $l$ und $r$.
%\end{enumerate}
%Der folgende Satz zeigt, wieviel Schlüssel ein Baum der Höhe $h$ höchstens enthalten
%kann.

%\begin{Satz}
%  Ein binärer Baum $b$ der Höhe $h$ enthält höchstens $2^h - 1$ Schlüssel.
%\end{Satz}
%\noindent
%\textbf{Beweis}:  Wir bezeichnen die maximale Anzahl Schlüssel eines Baums der Höhe $h$
%mit $c_h$.  Wir beweisen  durch Induktion nach $h$, dass gilt:
%\[ c_h = 2^h - 1. \]
%\begin{enumerate}
%\item[I.A.] $h = 0$: Der einzige Baum der Höhe $0$ ist $\textsl{Nil}$.
%            Dieser enthält $0$ Schlüssel.  Also gilt
%            \\[0.2cm]
%            \hspace*{1.3cm}
%            $c_0 = 0 = 2^0 - 1$.
%\item[I.S.] $h \mapsto h + 1$: Ein Baum der Höhe $h+1$, der die maximale Anzahl
%            Schlüssel enthält, hat die Form $\textsl{node}(k,v,l,r)$, wobei dann $l$ und
%            $r$  Bäume der Höhe $h$ sind, die die maximale Anzahl Schlüssel enthalten.
%            Folglich gilt:
%            \begin{eqnarray*}
%               c_{h+1} &               =  & 1 + c_h + c_h \\
%                       & \stackrel{IV}{=} & 1 + (2^h - 1) + (2^h - 1) \\
%                       &               =  & 2 \cdot 2^h - 1 \\
%                       &               =  & 2^{h+1} - 1. \hspace*{9cm} \Box
%            \end{eqnarray*}
%\end{enumerate}

%Die Höhe eines Baumes gibt ein Maß für die Komplexität der Methoden \textsl{find},
%\textsl{insert} und \textsl{delete}, denn bei einem Baum der Höhe $h$ sind für jede dieser
%Operationen höchstens $h$ Vergleiche von Schlüsseln erforderlich.

Wir bezeichnen die \underline{durchschnittliche} Anzahl von Vergleichen, die beim Aufruf
$b.\textsl{find}(k)$ für einen geordneten binären Baum $b$ durchgeführt werden müssen, falls $b$
insgesamt $n$ Schlüssel enthält, mit $d_n$.  Wir wollen annehmen, dass der Schlüssel $k$ auch
wirklich in $b$ zu finden ist.  Unser Ziel ist es, für $d_n$ eine Rekurrenz-Gleichung aufzustellen.
Zunächst
ist klar, dass \\[0.2cm]
\hspace*{1.3cm} $d_1 = 1$ \\[0.2cm]
ist, denn wenn der Baum $b$ nur einen Schlüssel enthält, wird genau einen Vergleich durchgeführt.
Wir betrachten nun einen binären Baum $b$, der $n+1$ Schlüssel enthält.  Dann hat $b$
die Form \\[0.2cm]
\hspace*{1.3cm} $b = \textsl{node}(k',v,l,r)$. \\[0.2cm]
Ordnen wir die $n+1$ Schlüssel der Größe nach in der Form 
\\[0.2cm]
\hspace*{1.3cm}
$k_0 < k_1 < \cdots < k_{i-1} < k_{i} < k_{i+1} < \cdots < k_{n-1} < k_n$,
\\[0.2cm]
so gibt es $n+1$ verschiedene Positionen, an denen
der Schlüssel $k'$ auftreten kann.  Wenn $k' = k_i$ ist, so enthält der
linke Teilbaum $i$ Schlüssel und der rechte Teilbaum enthält $n-i$ Schlüssel:
\\[0.2cm]
\hspace*{1.3cm}
$\underbrace{k_0 < k_1 < \cdots < k_{i-1}}_{\mbox{Schlüssel in $l$}} < 
 \underbrace{k_{i}}_{\stackrel{\displaystyle \shortparallel}{\displaystyle k'}} < 
 \underbrace{k_{i+1} < \cdots < k_{n-1} < k_n}_{\mbox{Schlüssel in $r$}}$,
\\[0.2cm]
Da $b$ insgesamt $n+1$ Schlüssel enthält, gibt es $n+1$ Möglichkeiten, wie die
verbleibenden $n$ Schlüssel auf die beiden Teilbäume $l$ und $r$ verteilt sein können, denn
$l$ kann $i$ Schlüssel enthalten, wobei \\[0.2cm]
\hspace*{1.3cm} $i \in \{0,1, \cdots, n\}$ \\[0.2cm]
gilt.  Entsprechend enthält $r$ dann $n-i$ Schlüssel.  
Bezeichnen wir die durchschnittliche Anzahl von Vergleichen bei einer Suche in einem Baum mit $n+1$
Schlüsseln, dessen linker Teilbaum $i$ Elemente hat, mit
\\[0.2cm]
\hspace*{1.3cm}
$\textsl{anzVgl}(i,\, n\!+\!1)$,
\\
so gilt
\\[-0.1cm]
\hspace*{1.3cm}
$\ds d_{n+1} =  \frac{1}{n+1} \cdot \sum\limits_{i=0}^n \textsl{anzVgl}(i,\, n\!+\!1)$,
\\[0.2cm]
denn wir haben ja angenommen, dass alle Werte von $i$ die gleiche Wahrscheinlichkeit,
nämlich $\frac{1}{n+1}$, haben.
\vspace*{0.1cm}

Berechnen wir nun den Wert von $\textsl{anzVgl}(i,n\!+\!1)$:
Falls $l$ aus $i$ Schlüsseln besteht und die restlichen $n-i$ Schlüssel in $r$ liegen,
so gibt es für den Schlüssel $k$, nach dem wir in dem Aufruf $b.\textsl{find}(k)$ suchen, 
$3$ Möglichkeiten:
\begin{enumerate}
\item $k$ kann mit dem Schlüssel $k'$ an der Wurzel des Baums übereinstimmen.
      In diesem Fall führen wir nur einen Vergleich durch.  Da es insgesamt
      $n+1$ Schlüssel in dem Baum gibt und nur in einem dieser Fälle
      der Schlüssel, den wir suchen, an der Wurzel steht, hat dieser Fall die
      Wahrscheinlichkeit
      \\[0.2cm]
      \hspace*{1.3cm} $\bruch{1}{\,n+1\,}$.

\item $k$ kann mit einem der $i$ Schlüssel im linken Teilbaum $l$ übereinstimmen.
      Da  der linke Teilbaum $i$ Schlüssel enthält und  es insgesamt
      $n+1$ Schlüssel gibt, hat die Wahrscheinlichkeit, dass $k$ in dem linken Teilbaum $l$
      auftritt, den Wert \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle\bruch{i}{n+1}$. \\[0.2cm]
       In diesem Fall werden \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle d_i + 1$ \\[0.2cm]
      Vergleiche durchgeführt, denn außer den $d_i$ Vergleichen mit den Schlüsseln aus dem
      linken Teilbaum muss der Schlüssel, der gesucht wird, ja noch mit dem Schlüssel an
      der Wurzel verglichen werden.
\item $k$ kann mit einem der $n-i$ Schlüssel im rechten Teilbaum $r$ übereinstimmen.

      Da  der rechte Teilbaum $n-i$ Schlüssel enthält und  es insgesamt
      $n+1$ Schlüssel gibt, hat die Wahrscheinlichkeit, dass $k$ in dem rechten Teilbaum $r$
      auftritt, den Wert \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle \bruch{n-i}{n+1}$. \\[0.2cm]
      Analog zum zweiten Fall werden diesmal \\[0.2cm]
      \hspace*{1.3cm} $\displaystyle d_{n-i} + 1$ \\[0.2cm]
      Vergleiche durchgeführt. 
\end{enumerate}
Um nun  $\textsl{anzVgl}(i, n\!+\!1)$ berechnen zu können, müssen wir in jedem der drei
Fälle die Wahrscheinlichkeit mit der Anzahl der Vergleiche multiplizieren und
die Werte, die sich für die drei Fälle ergeben, aufsummieren.  Wir erhalten
\begin{eqnarray*}
  \textsl{anzVgl}(i, n\!+\!1) 
& = & \bruch{1}{\,n+1\,} \cdot 1 + \bruch{i}{n+1} \cdot (d_i + 1) + \bruch{n-i}{n+1} \cdot (d_{n-i} + 1) 
      \\[0.2cm]
& = & \bruch{1}{\,n+1\,} \cdot \bigl(1 + i \cdot (d_i + 1) + (n-i) \cdot (d_{n-i} + 1)\bigr)      \\[0.2cm]
& = & \bruch{1}{\,n+1\,} \cdot \bigl(1 + i + (n-i) + i \cdot d_i + (n-i) \cdot d_{n-i} \bigr)    \\[0.2cm]
& = & \bruch{1}{\,n+1\,} \cdot \bigl(n + 1 + i \cdot d_i + (n-i) \cdot d_{n-i} \bigr)            \\[0.2cm]
& = & 1 + \bruch{1}{\,n+1\,} \cdot \bigl(i \cdot d_i + (n-i) \cdot d_{n-i} \bigr) 
\end{eqnarray*}


Damit können wir nun die Rekurrenz-Gleichung für $d_{n+1}$ aufstellen: 
\\[0.2cm]
\hspace*{1.3cm}
$
\begin{array}{lcl}
d_{n+1} 
& = &  
\ds\sum\limits_{i=0}^n \bruch{1}{\,n+1\,} \cdot \textsl{anzVgl}(i,\,n\!+\!1)  \\[0.5cm]
& = &  
\ds\bruch{1}{n+1} \cdot \sum\limits_{i=0}^n  
           \left(1 + \bruch{1}{n+1} \cdot \bigl(i \cdot d_i + (n-i) \cdot d_{n-i} \bigr) \right)
\\[0.5cm]
& = &  
\bruch{1}{n+1} \cdot \Biggl(\underbrace{\sum\limits_{i=0}^n 1}_{\stackrel{\displaystyle \shortparallel}{n+1}} \;+\;
           \bruch{1}{n+1} \cdot \ds\sum\limits_{i=0}^n \bigl(i \cdot d_i + (n-i) \cdot d_{n-i} \bigr) \Biggr)
\\[1.3cm]
& = &  
1 + \bruch{1}{(n+1)^2} \cdot \left(\ds\sum\limits_{i=0}^n \left(i\cdot d_i + (n-i)\cdot d_{n-i}\right) \right) 
\\[0.5cm]
& = &  
1 + \bruch{2}{(n+1)^2} \cdot \ds\sum\limits_{i=0}^n i\cdot d_i 
\end{array}
$
\\[0.2cm]
Bei der letzten Umformung haben wir die Gleichung  \\[0.2cm]
\hspace*{1.3cm}
$\ds\sum\limits_{i=0}^n f(n-i) = \sum\limits_{i=0}^n f(i)$ \\[0.2cm]
benutzt, die wir bei der Analyse der Komplexität von Quick-Sort gezeigt hatten.
Wir lösen jetzt die Rekurrenz-Gleichung 
\begin{equation}
  \label{eq:bin1}
d_{n+1} = \displaystyle 1 + \bruch{2}{(n+1)^2} \cdot \sum\limits_{i=0}^n i\cdot d_i  
\end{equation}
mit der Anfangs-Bedingungen $d_1 = 1$.  
Zur Lösung von Gleichung (\ref{eq:bin1}) führen wir die Substitution $n \mapsto n+1$ durch und erhalten 
\begin{equation}
  \label{eq:bin2}
d_{n+2} = \displaystyle 1 + \bruch{2}{(n+2)^2} \cdot \sum\limits_{i=0}^{n+1} i\cdot d_i  
\end{equation}
Wir multiplizieren nun Gleichung (\ref{eq:bin1}) mit $(n+1)^2$ und Gleichung (\ref{eq:bin2}) 
mit $(n+2)^2$ und finden die Gleichungen 
\begin{eqnarray}
  \label{eq:bin3}
(n+1)^2 \cdot d_{n+1} & = & (n+1)^2 + 2 \cdot \sum\limits_{i=0}^n i\cdot d_i, \\
  \label{eq:bin4}
(n+2)^2 \cdot d_{n+2} & = & (n+2)^2 + 2 \cdot \sum\limits_{i=0}^{n+1} i\cdot d_i
\end{eqnarray}
Subtrahieren wir Gleichung (\ref{eq:bin3}) von Gleichung (\ref{eq:bin4}),
so erhalten wir \\[0.2cm]
\hspace*{1.3cm} 
$(n+2)^2 \cdot d_{n+2} - (n+1)^2 \cdot d_{n+1} = (n+2)^2 - (n+1)^2 + 2 \cdot (n+1) \cdot d_{n+1}$.
\\[0.2cm]
Zur Vereinfachung substituieren wir hier $n \mapsto n - 1$ und erhalten \\[0.2cm]
\hspace*{1.3cm} 
$(n+1)^2 \cdot d_{n+1} - n^2 \cdot d_{n} = (n+1)^2 - n^2 + 2 \cdot n \cdot d_{n}$.
\\[0.2cm]
Dies vereinfachen wir zu \\[0.2cm]
\hspace*{1.3cm} $(n+1)^2 \cdot d_{n+1}  =  n \cdot (n + 2) \cdot d_{n} + 2 \cdot n + 1$. \\[0.2cm]
Bei dieser Gleichung teilen wir auf beiden Seiten durch $(n+2)\cdot (n+1)$ und bekommen \\[0.2cm]
\hspace*{1.3cm}  
$\displaystyle \bruch{n+1}{n+2} \cdot d_{n+1}  =  \bruch{n}{n + 1} \cdot d_{n} + \bruch{2 \cdot n + 1}{(n+2)\cdot (n+1)}$. \\[0.2cm]
Nun definieren wir \\[0.2cm]
\hspace*{1.3cm} $\displaystyle c_n = \bruch{n}{n+1} \cdot d_n$. \\[0.4cm]
Dann gilt $c_1 = \bruch{1}{2} \cdot d_1 = \bruch{1}{2}$ und wir  haben die Rekurrenz-Gleichung \\[0.2cm]
\hspace*{1.3cm} 
$\displaystyle c_{n+1}  =  c_{n} + \frac{2 \cdot n + 1}{(n+2)\cdot (n+1)}$. \\[0.2cm]
Durch Partialbruch-Zerlegung finden wir \\[0.2cm]
\hspace*{1.3cm} 
$\displaystyle \frac{2 \cdot n + 1}{(n+2)\cdot (n+1)} = \frac{3}{n+2} - \frac{1}{n+1}$. \\[0.2cm]
Also haben wir \\[0.2cm]
\hspace*{1.3cm} $\displaystyle c_{n+1} = c_n +  \frac{3}{n+2} - \frac{1}{n+1}$. \\[0.2cm]
Wegen $c_1 = \bruch{1}{2}$ ist die Gleichung auch für $n=0$ richtig, wenn wir $c_0 = 0$ setzen, denn es gilt
\\[0.2cm]
\hspace*{1.3cm}
$\bruch{1}{2} = 0 + \bruch{3}{0+2} - \bruch{1}{0+1}$.
\\[0.2cm]
Die Rekurrenz-Gleichung für $c_n$ können wir mit dem Teleskop-Verfahren lösen:
\begin{eqnarray*}  
  c_{n+1} & = & c_0 + \sum\limits_{i=0}^{n} \frac{3}{i+2} - \sum\limits_{i=0}^{n} \frac{1}{i+1} 
\\[0.2cm]
          & = & \sum\limits_{i=2}^{n+2} \frac{3}{i} - \sum\limits_{i=1}^{n+1} \frac{1}{i}.
\end{eqnarray*}
Wir substituieren $n \mapsto n-1$ und vereinfachen dies zu 
\\[0.2cm]
\hspace*{1.3cm}
$c_{n} =  \displaystyle\sum\limits_{i=2}^{n+1} \frac{3}{i} - \sum\limits_{i=1}^{n} \frac{1}{i}$
\\[0.2cm]
Die harmonische Zahl $H_n$ ist als
$H_n = \ds\sum\limits_{i=1}^{n} \bruch{1}{i}$   
definiert.  Wir können $c_n$ auf $H_n$ zurückführen: 
\\[0.2cm]
\hspace*{1.3cm}
$c_n = \ds 3 \cdot H_n - \frac{3}{1} + \frac{3}{n+1} - H_n  =  \ds 2 \cdot H_n - 3 \cdot \frac{n}{n+1}$
\\[0.2cm] 
Wegen $H_n = \displaystyle\sum\limits_{i=1}^{n} \frac{1}{i} = \ln(n) + \Oh(1)$ und $\ds 3 \cdot\frac{n}{n+1} \in \Oh(1)$
gilt dann \\[0.3cm]
\hspace*{1.3cm} 
$\displaystyle c_n = 2 \cdot \ln(n) + \Oh(1)$.
\\[0.3cm]
Berücksichtigen wir  $d_n = \bruch{n+1}{n}\cdot c_n$, so finden wir für große $n$ ebenfalls \\[0.2cm]
\hspace*{1.3cm} $\displaystyle d_n = 2 \cdot \ln(n) + \Oh\bigl(1\bigr)$.
\\[0.2cm]
Das ist unser zentrales Ergebnis: Im Durchschnitt erfordert das Suchen in einem zufällig
erzeugten geordneten binären Baum für große Werte von $n$ etwa 
\\[0.2cm]
\hspace*{1.3cm}
$2 \cdot \ln(n) = 2 \cdot \ln(2) \cdot \log_2(n) \approx 1.386 \cdot \log_2(n)$ 
\\[0.2cm]
Vergleiche.  Damit werden etwa 39 \% 
mehr Vergleiche ausgeführt als bei einem optimal balancierten binären Baum.
Ähnliche Ergebnisse können wir für das Einfügen oder Löschen erhalten.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "algorithms"
%%% End: 
